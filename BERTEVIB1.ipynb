{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa95efb4-71eb-4f3d-8799-c12831385900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e375e916-07a1-44f1-9675-8fb7eb8045f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semente para reprodutibilidade\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b511a6a-4c56-4335-8c15-660d3d146399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configurações gerais\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')\n",
    "nclasses = 2  # Número de classes\n",
    "nepochs = 10  # Épocas\n",
    "batch_size = 16  # Tamanho dos lotes\n",
    "batch_status = 32  # Frequência de exibição de status\n",
    "learning_rate = 2e-5  # Taxa de aprendizado mais comum para BERT\n",
    "early_stop = 5  # Critério de parada antecipada\n",
    "max_length = 360  # Comprimento máximo das sequências\n",
    "write_path = 'model'  # Diretório para salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0a71c0-667a-421f-b324-fa857999aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv(\"DATAFRAME.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f8fd60-955b-45a5-804d-4fcbba2a666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Treino: 1177\n",
      "Tamanho da Validação: 169\n",
      "Tamanho do Teste: 150\n"
     ]
    }
   ],
   "source": [
    "# Divisão dos dados (ex: 80% treino, 10% val, 10% teste)\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=seed, stratify=data['contra'])\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.125, random_state=seed, stratify=train_data['contra'])\n",
    "\n",
    "print(f\"Tamanho do Treino: {len(train_data)}\")\n",
    "print(f\"Tamanho da Validação: {len(val_data)}\")\n",
    "print(f\"Tamanho do Teste: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7f8d91-5750-45f3-9a75-1240e5401757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe personalizada para o dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['contra']\n",
    "        inputs = self.tokenizer(text, return_tensors='pt',\n",
    "                                padding='max_length', truncation=True,\n",
    "                                max_length=self.max_length)\n",
    "        return {key: val.squeeze(0) for key, val in inputs.items()}, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac08faef-e9c9-496f-b850-6295f892c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo customizado com camadas extras\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, model_name, nclasses):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, nclasses)\n",
    "\n",
    "        # Congelar todas as camadas do BERT inicialmente\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Descongelar as últimas 4 camadas\n",
    "        for param in self.bert.encoder.layer[-4:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        dropped_out = self.dropout(pooled_output)\n",
    "        logits = self.classifier(dropped_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ce6958-e51e-435d-bf3a-4a2f21a7751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a16fa8b6cd47808d75bd0a7439360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\renat\\.cache\\huggingface\\hub\\models--neuralmind--bert-base-portuguese-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c103c5e865d8452fb853bb9cfa6c4f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcfda9b347b48fda20566ecdab3bd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85699ca88362422ab0084830cfc3a9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0a9c82642d4876ba1fe78c73180a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7714a29ccbc46afb7743ec15cce8214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicializar o tokenizador e o modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
    "model = CustomBERTModel('neuralmind/bert-base-portuguese-cased', nclasses).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a01c80e-7cdf-47e9-8c8b-6cb250ae74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o otimizador apenas para os parâmetros treináveis\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbc16ca-d641-4115-8bdc-02d592c42f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de perda com pesos para classes desbalanceadas (ajuste conforme necessário)\n",
    "class_weights = torch.tensor([1.0, 2.5]).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eac143f-845f-4392-9392-e694b05bb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar datasets e dataloaders\n",
    "train_dataset = CustomDataset(train_data, tokenizer, max_length)\n",
    "val_dataset = CustomDataset(val_data, tokenizer, max_length)\n",
    "test_dataset = CustomDataset(test_data, tokenizer, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2581ca45-3dbc-483b-a002-c89c5ba7184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valdata = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "testdata = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29944c32-f333-4903-b5db-2a5c2fd9ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação (retorna F1 e Acurácia)\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_real, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(**inputs)\n",
    "            pred_labels = torch.argmax(logits, 1)\n",
    "\n",
    "            y_real.extend(labels.cpu().tolist())\n",
    "            y_pred.extend(pred_labels.cpu().tolist())\n",
    "\n",
    "    f1 = f1_score(y_real, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_real, y_pred)\n",
    "    return f1, acc, (y_real, y_pred)\n",
    "\n",
    "if not os.path.exists(write_path):\n",
    "    os.makedirs(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc85ef1-43a5-4063-a2db-02b5fe668b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 [32/74]\tLoss: 0.701079\n",
      "Epoch: 0 [64/74]\tLoss: 0.441900\n",
      "Epoch 0 - Val F1: 0.4756, Val Accuracy: 0.5621\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 1 [32/74]\tLoss: 0.445746\n",
      "Epoch: 1 [64/74]\tLoss: 0.378276\n",
      "Epoch 1 - Val F1: 0.8574, Val Accuracy: 0.8580\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 2 [32/74]\tLoss: 0.361751\n",
      "Epoch: 2 [64/74]\tLoss: 0.562474\n",
      "Epoch 2 - Val F1: 0.8693, Val Accuracy: 0.8698\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 3 [32/74]\tLoss: 0.099081\n",
      "Epoch: 3 [64/74]\tLoss: 0.070618\n",
      "Epoch 3 - Val F1: 0.8699, Val Accuracy: 0.8698\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 4 [32/74]\tLoss: 0.112896\n",
      "Epoch: 4 [64/74]\tLoss: 0.022936\n",
      "Epoch 4 - Val F1: 0.8695, Val Accuracy: 0.8698\n",
      "Epoch: 5 [32/74]\tLoss: 0.014355\n",
      "Epoch: 5 [64/74]\tLoss: 0.023717\n",
      "Epoch 5 - Val F1: 0.8758, Val Accuracy: 0.8757\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 6 [32/74]\tLoss: 0.021397\n",
      "Epoch: 6 [64/74]\tLoss: 0.005652\n",
      "Epoch 6 - Val F1: 0.8758, Val Accuracy: 0.8757\n",
      "Epoch: 7 [32/74]\tLoss: 0.183824\n",
      "Epoch: 7 [64/74]\tLoss: 0.048634\n",
      "Epoch 7 - Val F1: 0.8876, Val Accuracy: 0.8876\n",
      "Novo melhor modelo salvo.\n",
      "Epoch: 8 [32/74]\tLoss: 0.004811\n",
      "Epoch: 8 [64/74]\tLoss: 0.014074\n",
      "Epoch 8 - Val F1: 0.8697, Val Accuracy: 0.8698\n",
      "Epoch: 9 [32/74]\tLoss: 0.002207\n",
      "Epoch: 9 [64/74]\tLoss: 0.185642\n",
      "Epoch 9 - Val F1: 0.8446, Val Accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_9280\\3529535097.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(write_path, 'best_model.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho no conjunto de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82        79\n",
      "           1       0.80      0.79      0.79        71\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.81      0.81      0.81       150\n",
      "weighted avg       0.81      0.81      0.81       150\n",
      "\n",
      "F1 (teste): 0.8066, Accuracy (teste): 0.8067\n"
     ]
    }
   ],
   "source": [
    "max_f1, repeat = 0, 0\n",
    "for epoch in range(nepochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(traindata):\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(**inputs)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (batch_idx + 1) % batch_status == 0:\n",
    "            print(f'Epoch: {epoch} [{batch_idx + 1}/{len(traindata)}]\\tLoss: {loss:.6f}')\n",
    "\n",
    "    # Avaliação no conjunto de validação\n",
    "    f1_val, acc_val, _ = evaluate(model, valdata)\n",
    "    print(f'Epoch {epoch} - Val F1: {f1_val:.4f}, Val Accuracy: {acc_val:.4f}')\n",
    "\n",
    "    # Early Stopping baseado no Val F1\n",
    "    if f1_val > max_f1:\n",
    "        torch.save(model.state_dict(), os.path.join(write_path, 'best_model.pth'))\n",
    "        max_f1 = f1_val\n",
    "        repeat = 0\n",
    "        print('Novo melhor modelo salvo.')\n",
    "    else:\n",
    "        repeat += 1\n",
    "\n",
    "    if repeat == early_stop:\n",
    "        print('Early stopping atingido.')\n",
    "        break\n",
    "\n",
    "# Avaliar no conjunto de teste final com o melhor modelo\n",
    "model.load_state_dict(torch.load(os.path.join(write_path, 'best_model.pth')))\n",
    "f1_test, acc_test, (y_real, y_pred) = evaluate(model, testdata)\n",
    "print(\"Desempenho no conjunto de teste:\")\n",
    "print(classification_report(y_real, y_pred, target_names=['0', '1']))\n",
    "print(f\"F1 (teste): {f1_test:.4f}, Accuracy (teste): {acc_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
